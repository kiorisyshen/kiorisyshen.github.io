<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=""><title>Neural Network III Backpropagation | Kio's Spot</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script src="https://www.googletagmanager.com/gtag/js?id=UA-160042218-1" async></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-160042218-1');
</script><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"><div class="darkmode-toggle">üåì</div><script>var prefersDarkMode = window.matchMedia('(prefers-color-scheme: dark)');
var toggle = document.querySelector('.darkmode-toggle');
var html = document.querySelector('html');

html.dataset.dark = localStorage.dark || prefersDarkMode.matches;

toggle.addEventListener('click', () => {
localStorage.dark = !(html.dataset.dark == 'true');
html.dataset.dark = localStorage.dark;
});</script><meta name="generator" content="Hexo 6.2.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Neural Network III Backpropagation</h1><a id="logo" href="/.">Kio's Spot</a><p class="description">ÊÖ¢ÊÖ¢ÂâçËøõ Move forward gradually</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Neural Network III Backpropagation</h1><div class="post-meta">2016-04-01<span> | </span><span class="category"><a href="/categories/Machine-Learning/">Machine Learning</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 663</span><span class="post-meta-item-text"> Words</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 4</span><span class="post-meta-item-text"> Minutes</span></span></span></div><a class="disqus-comment-count" data-disqus-identifier="2016/04/01/Neural Network III Backpropagation/" href="/2016/04/01/Neural%20Network%20III%20Backpropagation/#disqus_thread"></a><div class="post-content"><p>This is a note for learning Neural Network in Machine Learning based on this <a target="_blank" rel="noopener" href="https://www.coursera.org/course/neuralnets">course</a> on <a target="_blank" rel="noopener" href="https://www.coursera.org">Coursera</a>.</p>
<h2 id="Learning-weights-of-perceptron">Learning weights of perceptron</h2>
<p>Different to the learning procedure for perceptron in the post before, here is a new way for learning. Instead of showing the weights get closer to a good set of weights, show that the actual output values get closer the target values.</p>
<p>The advantage of this method is that it is the fundamentals towards building a learning algorithm for multiple layers neural network.</p>
<h3 id="linear-neuron">linear neuron</h3>
<p>This is the batch delta rule for changing weights.<br>
Definition:<br>
$$y=\sum_{i}w_i x_i$$</p>
<p>x is input vector, y is output, w is weight vector. The definition of the squared error:<br>
$$E=\frac{1}{2}\sum_{n\in{training}}(t_n-y_n)^2$$</p>
<p>t is the target value for each training case. So, we need to derive the value of gradient $\frac{\partial E}{\partial w_i}$, So,<br>
$$\frac{\partial{E}}{\partial{w_i}} = \frac{1}{2}\sum_{n\in{training}}\frac{\partial y_n}{\partial w_i}\frac{dE_n}{dy_n} = -\sum_{n\in{training}}x_{i(n)}(t_n-y_n)$$<br>
Then we add a learning rate $\epsilon$ to the small change on w:<br>
$$\Delta w_i = -\epsilon\frac{\partial E}{\partial w_i}=\sum_{n\in{training}}\epsilon x_{i(n)}(t_n-y_n)$$</p>
<h3 id="Logistic-neuron">Logistic neuron</h3>
<p>Definition:<br>
$$y=\sum_{i}w_i x_i$$<br>
$$y=\frac{1}{1+e^{-\beta z}}\Rightarrow \frac{dy}{dz} = y(1-y)$$<br>
$$E=\frac{1}{2}\sum_{n\in{training}}(t_n-y_n)^2$$<br>
So,<br>
$$\frac{\partial{E}}{\partial{w_i}} = \sum_n\frac{\partial y_n}{\partial w_i}\frac{\partial E}{\partial y_n} = \sum_n\frac{\partial z_n}{\partial w_i}\frac{dy_n}{dz_n}\frac{\partial E}{\partial y_n} = -\sum_n x_{i(n)}y_n(1-y_n)(t_n-y_n)$$</p>
<h2 id="Backpropagation-algorithm">Backpropagation algorithm</h2>
<p>In order to get nonlinear function for the NN and make machine to learn the feature, we need to add hidden layer to our NN framework. Thus we need an algorithm to adjust all hidden layers‚Äô weights efficiently.</p>
<p>The idea behind backpropagation is that though we don t know what the hidden units ought to do, but we can compute how fast the error changes as we change a hidden activity. Here is the procedure:</p>
<img src="/2016/04/01/Neural%20Network%20III%20Backpropagation/Backpropagation.png" class="">
<p><em>The j represent the current layer, the i represent the layer before current layer</em>. The definition of error function:<br>
$$E=\frac{1}{2}\sum_{j\in{output}}(t_j-y_j)^2$$<br>
thus,</p>
<p>$$\frac{\partial E}{\partial w_{ij}} = \frac{\partial z_j}{\partial w_{ij}}\frac{\partial E}{\partial z_j} = y_i \frac{\partial{E}}{\partial z_j} = y_i \frac{\partial y_j}{\partial z_j}\frac{\partial E}{\partial y_j} = y_i y_j(1-y_j)\frac{\partial E}{\partial y_j} = y_i y_j(1-y_j)[-(t_j-y_j)] $$</p>
<p>For computing further layers, we need to derive $\frac{\partial E}{\partial y_i}$, so,<br>
$$\frac{\partial E}{\partial y_i} = \sum_j \frac{dz_j}{dy_i}\frac{\partial E}{\partial z_j} = \sum_j w_{ij}\frac{\partial E}{\partial z_j} = \sum_j w_{ij}y_j(1-y_j)[-(t_j-y_j)]$$<br>
Now, with $\frac{\partial E}{\partial y_i}$, we could do the iterate things back to layers close to input layers.</p>
<h2 id="Issues-in-using-Backpropagation">Issues in using Backpropagation</h2>
<p>These two issue will be discussed in the later lectures.</p>
<h3 id="Optimization-issues">Optimization issues</h3>
<p>How do we use the error derivatives on individual cases to discover a good set of weights?</p>
<ul>
<li>How often to update the weights</li>
<li>Online: after each training case.</li>
<li>Full batch: after a full sweep through the training data.</li>
<li>Mini-batch: after a small sample of training cases.</li>
<li>How much to update</li>
<li>Using fixed learning rate?</li>
</ul>
<h3 id="Generalization-issues">Generalization issues</h3>
<p>How do we ensure that the learned weights work well for cases we did not see during training?</p>
<ul>
<li>Overfitting</li>
<li>Because a NN is flexible, so we need to prevent it to be overfitted.</li>
<li>A large number of different methods to tackle this problem.</li>
</ul>
<h2 id="Supplement">Supplement</h2>
<p>The backpropagation algorithm is improved by Hinton and other workers in 1985. See this paper for more details:<br>
LEARNING INTERNAL REPRESENTATIONS BY ERROR PROPAGATION, David E. Ruineihart, Geoffrey E. Hinton, and Ronald J. Williams, September 1985, ICS Report 8506</p>
</div><div class="tags"><a href="/tags/Learning note"><i class="fa fa-tag">Learning note</i></a><a href="/tags/Neural Network"><i class="fa fa-tag">Neural Network</i></a></div><div class="post-nav"><a class="pre" href="/2018/08/27/Vector%20Swizzling%20and%20Parameter%20Pack%20in%20C++/">Vector Swizzling and Parameter Pack in C++</a><a class="next" href="/2016/03/29/Neural%20Network%20II%20Architecture%20&amp;%20Perceptrons/">Neural Network II Architecture &amp; Perceptrons</a></div><link rel="stylesheet" type="text/css" href="https://unpkg.com/disqusjs@1.3/dist/disqusjs.css"><script type="text/javascript" src="https://unpkg.com/disqusjs@1.3/dist/disqus.js"></script><script type="text/javascript" id="disqus-count-script">$(function() {
  var xhr = new XMLHttpRequest();
  xhr.open('GET', '//disqus.com/next/config.json', true);
  xhr.timeout = 2500;
  xhr.onreadystatechange = function () {
    if (xhr.readyState === 4 && xhr.status === 200) {
      $('.post-meta .post-comments-count').show();
      var s = document.createElement('script');
      s.id = 'dsq-count-scr';
      s.src = 'https://kiosspot.disqus.com/count.js';
      s.async = true;
      (document.head || document.body).appendChild(s);
    }
  };
  xhr.ontimeout = function () { xhr.abort(); };
  xhr.send(null);
});</script><div class="comments" id="disqus_thread"><script type="text/javascript">// Load comments with DisqusJS
function loadComments() {
  window.dsqjs = new DisqusJS({
    shortname: 'kiosspot',
    siteName: 'Kio\'s Spot',
    identifier: '2016/04/01/Neural Network III Backpropagation/',
    url: 'http://kiorisyshen.github.io/2016/04/01/Neural Network III Backpropagation/',
    title: 'Neural Network III Backpropagation',
    api: '',
    apikey: '',
    admin: '',
    adminLabel: ''
  });
}
// Lazy load {# Credit: https://github.com/theme-next/hexo-theme-next/blob/master/layout/_third-party/comments/disqus.swig #}
(function () {
  var offsetTop = document.getElementById('disqus_thread').offsetTop - window.innerHeight;
  if (offsetTop <= 0) {
    // Load directly when there's no scrollbar
    window.addEventListener('load', loadComments, false);
  } else {
    var disqusScroll = function () {
      // offsetTop may changes because of manually resizing browser window or lazy loading images
      var offsetTop = document.getElementById('disqus_thread').offsetTop - window.innerHeight;
      var scrollTop = window.scrollY;

      // Pre-load comments a bit? (margin or anything else)
      if (offsetTop - scrollTop < 60) {
        window.removeEventListener('scroll', disqusScroll);
        loadComments();
      }
    };
    window.addEventListener('scroll', disqusScroll);
  }
})();
// Scroll to comments automatically if #comment-xxx anchor specified
window.addEventListener('load', function () {
  // I don't know why, it just works.
  window.setTimeout(function () {
    if (location.hash.indexOf('#comment-') !== -1) {
      document.getElementById('disqus_thread').scrollIntoView(true);
    }
  }, 100);
}, false);
</script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://kiorisyshen.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/C/">C++</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/C/Lidar/">Lidar</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Graphics/">Computer Graphics</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Image-Processing/">Image Processing</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Multi-view-Geometry/">Multi-view Geometry</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/Coding-Note/" style="font-size: 15px;">Coding Note</a> <a href="/tags/C-Gaming/" style="font-size: 15px;">C++ Gaming</a> <a href="/tags/OpenGL/" style="font-size: 15px;">OpenGL</a> <a href="/tags/Metal/" style="font-size: 15px;">Metal</a> <a href="/tags/Learning-note/" style="font-size: 15px;">Learning note</a> <a href="/tags/Neural-Network/" style="font-size: 15px;">Neural Network</a> <a href="/tags/Paper/" style="font-size: 15px;">Paper</a> <a href="/tags/ROS/" style="font-size: 15px;">ROS</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-comment-o"> Recent Comments</i></div><script type="text/javascript" src="//kiosspot.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://silentming.net/" title="SilentMing's Gensokyo" target="_blank">SilentMing's Gensokyo</a><ul></ul><a href="https://unlimitedcodeworks.xyz/" title="Unlimited Code Works" target="_blank">Unlimited Code Works</a><ul></ul><a href="https://blog.icehoney.me/" title="Èõ™ÊúàÁßãÊ∞¥" target="_blank">Èõ™ÊúàÁßãÊ∞¥</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright ¬© 2022 <a href="/." rel="nofollow">Kio's Spot.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="Copy Successed!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>